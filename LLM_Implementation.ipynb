{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLWjQsiFTzFI2ARxndKaKU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinaxiG/Information-Extraction-from-Scanned-PDF/blob/main/LLM_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.auth import default\n",
        "creds, _ = default()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7xPxHsF6Q-g",
        "outputId": "918e379b-e9eb-4ae5-9e03-3b30cd4c9520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4b-WC4u6A3y",
        "outputId": "4ddba5da-c0ae-4ea6-f89a-f977e63bb215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/EC3.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Engineer Report1.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Engineer Report2.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Leese Deed.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Registry.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Architect Certificate.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Gantt Chart Mantra.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Affidavit 2.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Document 30 - Carpet Area & Floor plan.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Document 32 - Carpet Area & Floor plan - 3BHK.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Document 39 - Carpet Area & Floor plan - 2BHK.pdf\n",
            "/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Registry2.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def get_all_file_paths(folder_path):\n",
        "    file_paths = []\n",
        "\n",
        "    # Walk through all the directories and files in the specified folder\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file_name in files:\n",
        "            # Construct the full file path\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            file_paths.append(file_path)\n",
        "\n",
        "    return file_paths\n",
        "\n",
        "# Define the path to the folder\n",
        "extracted_files_folder = '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2'\n",
        "all_file_paths = get_all_file_paths(extracted_files_folder)\n",
        "\n",
        "# Print all file paths\n",
        "for path in all_file_paths:\n",
        "    print(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_file_paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ9ago-09Oyb",
        "outputId": "6a995dae-3119-4d63-da44-cffbb895dc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/EC3.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Engineer Report1.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Engineer Report2.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Leese Deed.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Registry.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Architect Certificate.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Gantt Chart Mantra.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Affidavit 2.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Document 30 - Carpet Area & Floor plan.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Document 32 - Carpet Area & Floor plan - 3BHK.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Document 39 - Carpet Area & Floor plan - 2BHK.pdf',\n",
              " '/content/drive/MyDrive/UX Research Studies/Magic Homes & RERA/Python | Query & Extract info from scanned docs/OCR Extracted Files/Mahagun Mantra 2/Registry2.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install needed modules for LLM implementation\n",
        "!pip install langchain_openai\n",
        "!pip install pikepdf opencv-python pypdf pdfminer.six unstructured pdf2image sentence-transformers unstructured-inference\n",
        "!pip install langchain\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--BWOpch7CN9",
        "outputId": "49a62f90-9f0e-4591-c1c6-df373bb21c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.21)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.29 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.2.29)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.40.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (0.1.98)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.29->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.29->langchain_openai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain_openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (9.1.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (20231228)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: unstructured-inference in /usr/local/lib/python3.10/dist-packages (0.7.36)\n",
            "Requirement already satisfied: Pillow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from pikepdf) (10.4.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf) (1.2.14)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.10/dist-packages (from pikepdf) (4.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pikepdf) (24.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.8)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.12.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.6)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.25.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: layoutparser in /usr/local/lib/python3.10/dist-packages (from unstructured-inference) (0.3.4)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference) (0.0.9)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from unstructured-inference) (1.16.2)\n",
            "Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference) (1.18.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from unstructured-inference) (3.7.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from unstructured-inference) (1.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference) (2.1.4)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference) (0.1.10)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from layoutparser->unstructured-inference) (0.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->unstructured-inference) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.7.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->unstructured-inference) (0.18.1+cu121)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (7.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.0)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured) (4.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference) (10.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser->unstructured-inference) (2.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser->unstructured-inference) (2024.1)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser->unstructured-inference) (4.30.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.29)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
            "Using cached langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "Using cached langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.2.12 langchain-text-splitters-0.2.2\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Modules\n",
        "!pip install langchain_community\n",
        "!pip install pillow-heif\n",
        "!pip install faiss-gpu # Or faiss-cpu depending on your system\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMkSRAv07Qy3",
        "outputId": "92666712-9e5f-4019-ea25-f6d207826c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.29)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.98)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.11\n",
            "Collecting pillow-heif\n",
            "  Downloading pillow_heif-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pillow>=10.1.0 in /usr/local/lib/python3.10/dist-packages (from pillow-heif) (10.4.0)\n",
            "Downloading pillow_heif-0.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow-heif\n",
            "Successfully installed pillow-heif-0.18.0\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"transformers.tokenization_utils_base\")\n"
      ],
      "metadata": {
        "id": "TDM6enks7kU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging face key\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
      ],
      "metadata": {
        "id": "OOucB_fY7mFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pipeline\n",
        "\n",
        "1. Parse the PDF file and load the data\n",
        "2. Split the data into chunks of fixed size.\n",
        "3. Embed the text using an embedding model.\n",
        "4. For each query, find the relevant chunk of text from the data. This is called as context.\n",
        "5. Define the Large Language Model (LLM).\n",
        "6. Using Prompt Engineering, generate a template for query which explicitly asks the LLM to search the asnwer given the context.\n",
        "7. Ask the query to LLM and get the answer.\n",
        "\n"
      ],
      "metadata": {
        "id": "G2VDwzzX7wcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LLM_preprocessor(file_path):\n",
        "  # loading the data\n",
        "  loader = UnstructuredPDFLoader(file_path)\n",
        "  data = loader.load()\n",
        "\n",
        "  #splitting the data\n",
        "  from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      chunk_size=500,\n",
        "      chunk_overlap=20,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "  docs = text_splitter.split_documents(data)\n",
        "\n",
        "  # Embed the text\n",
        "  embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "  db = FAISS.from_documents(docs, embeddings_model)\n",
        "\n",
        "  llm = HuggingFaceHub(\n",
        "      repo_id= \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "      task=\"text-generation\",\n",
        "      model_kwargs={\n",
        "          \"max_new_tokens\": 250,\n",
        "          \"top_k\": 30,\n",
        "          \"temperature\": 0.1,\n",
        "          \"repetition_penalty\": 1.03,\n",
        "      },\n",
        "  )\n",
        "\n",
        "  template = \"\"\"answer the following question : {question}\n",
        "\n",
        "  Only base your answer based on the provided information :\n",
        "\n",
        "  {context}\n",
        "\n",
        "  Answer: \"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"question\", 'context'])\n",
        "  llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "  return db, llm_chain\n",
        "\n",
        "def prettyprint(response):\n",
        "    ans_idx = response.find('Answer')\n",
        "    return response[ans_idx:]\n"
      ],
      "metadata": {
        "id": "ZrESb6Cw7oob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "\n",
        "def get_google_sheet(sheet_id, gc):\n",
        "    \"\"\"Open the Google Sheet using its ID.\"\"\"\n",
        "    spreadsheet = gc.open_by_key(sheet_id)\n",
        "    return spreadsheet.sheet1\n",
        "\n",
        "def get_queries(worksheet):\n",
        "    \"\"\"Extract queries from the first row (header) of the worksheet.\"\"\"\n",
        "    rows = worksheet.get_all_values()\n",
        "    header = rows[0][1:]\n",
        "    print(header)\n",
        "    return {i: header[i] for i in range(len(header))}\n",
        "\n",
        "def get_existing_responses(worksheet):\n",
        "    \"\"\"Get existing data from the Google Sheet.\"\"\"\n",
        "    existing_data = worksheet.get_all_values()\n",
        "    header = existing_data[0]  # Assuming the first row is the header\n",
        "    existing_responses = {}\n",
        "    for row in existing_data[1:]:\n",
        "        project_name = row[0]  # Assuming the first column is the project name\n",
        "        existing_responses[project_name] = row[1:]  # The rest are the responses\n",
        "    return existing_responses\n",
        "\n",
        "def prepare_row_responses(project_name, queries, existing_responses):\n",
        "    \"\"\"Prepare a dictionary to hold responses for the current row.\"\"\"\n",
        "    row_responses = {q: None for q in queries.values()}\n",
        "\n",
        "    if project_name in existing_responses:\n",
        "        existing_project_responses = existing_responses[project_name]\n",
        "        for i, query in enumerate(queries.values()):\n",
        "            if i < len(existing_project_responses) and existing_project_responses[i].strip():\n",
        "                row_responses[query] = existing_project_responses[i]\n",
        "\n",
        "    return row_responses\n",
        "\n",
        "def get_valid_answer(query, all_file_paths, LLM_preprocessor):\n",
        "    \"\"\"Get a valid answer for the query from the files.\"\"\"\n",
        "    for output_file_path in all_file_paths:\n",
        "        DB, LLM_Chain = LLM_preprocessor(output_file_path)\n",
        "        relevant_docs = DB.similarity_search(query, k=5)\n",
        "        response = LLM_Chain({\"question\": query, 'context': relevant_docs})['text']\n",
        "        pretty_response = prettyprint(response).replace('\\n', ' ').replace('\\r', '').strip()\n",
        "\n",
        "        if pretty_response.lower().startswith('answer:'):\n",
        "            pretty_response = pretty_response[7:].strip()\n",
        "\n",
        "        if \"not\" in pretty_response.lower() or \"not mentioned\" in pretty_response.lower():\n",
        "            response = pretty_response\n",
        "        else:\n",
        "            return pretty_response\n",
        "\n",
        "    return response  # Return the valid response\n",
        "    # return None\n",
        "\n",
        "def write_responses_to_sheet(worksheet, project_name, queries, row_responses, existing_responses):\n",
        "    \"\"\"Write the responses to the Google Sheet.\"\"\"\n",
        "    import string\n",
        "\n",
        "    row_responses_list = [project_name] + [row_responses[q] for q in queries.values()]\n",
        "\n",
        "    if project_name in existing_responses:\n",
        "        row_index = None\n",
        "        for idx, row in enumerate(worksheet.get_all_values()):\n",
        "            if row[0] == project_name:\n",
        "                row_index = idx + 1\n",
        "                break\n",
        "\n",
        "        if row_index is not None:\n",
        "            # Calculate the ending column dynamically based on the length of row_responses_list\n",
        "            start_col = 'A'\n",
        "            end_col = string.ascii_uppercase[len(row_responses_list) - 1]  # Adjusts the range dynamically\n",
        "            range_to_update = f'{start_col}{row_index}:{end_col}{row_index}'\n",
        "\n",
        "            # Update the existing row in the Google Sheet\n",
        "            worksheet.update(range_to_update, [row_responses_list])\n",
        "        else:\n",
        "            print(f\"Project name {project_name} was not found, appending a new row.\")\n",
        "            worksheet.append_row(row_responses_list)\n",
        "    else:\n",
        "        # Append the row if the project is not already in the sheet\n",
        "        print(f\"Project name {project_name} was not found, appending a new row.\")\n",
        "        worksheet.append_row(row_responses_list)\n",
        "\n",
        "    print(\"Responses written to Google Sheet successfully.\")\n",
        "\n",
        "\n",
        "# Main execution\n",
        "def main(sheet_id, all_file_paths, LLM_preprocessor):\n",
        "    gc = gspread.authorize(creds)  # Initialize your Google Sheets API client\n",
        "    worksheet = get_google_sheet(sheet_id, gc)\n",
        "    queries = get_queries(worksheet)\n",
        "    existing_responses = get_existing_responses(worksheet)\n",
        "\n",
        "    project_name = os.path.basename(os.path.dirname(all_file_paths[0]))\n",
        "    row_responses = prepare_row_responses(project_name, queries, existing_responses)\n",
        "\n",
        "    for q in queries.values():\n",
        "        if row_responses[q] is not None:\n",
        "            continue  # Skip already answered queries\n",
        "\n",
        "        row_responses[q] = get_valid_answer(q, all_file_paths, LLM_preprocessor)\n",
        "        write_responses_to_sheet(worksheet, project_name, queries, row_responses, existing_responses)\n"
      ],
      "metadata": {
        "id": "xZ0vOkvNAl0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_id = '10Sr4Kmu0rpyRuoZ6fTya1ELp310_mAzY0gSLQK6gGAM'\n",
        "main(sheet_id, all_file_paths, LLM_preprocessor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n43VWmnMAoIx",
        "outputId": "b8373824-c374-4998-84bb-683b93d640a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Who is the land owner?', 'Is it clear title?', 'Are there any pending approvals?', 'What is the completion status of the project?', 'What does the engineer report say?', 'What is the carpet area of 2 BHK?', 'Carpet area of 4 BHK?']\n",
            "Responses written to Google Sheet successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-ee9e48b5703a>:77: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  worksheet.update(range_to_update, [row_responses_list])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is it clear title?\n",
        "# What is the completion status of the project?,\n",
        "# What does the engineer report say?\n",
        "# Are there any pending approvals?,\n",
        "# What is the carpet area for 4BHK?,\n",
        "# What is the carpet area & balcony area for a 2 BHK unit?"
      ],
      "metadata": {
        "id": "dFbOZZ5YtF7P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}